{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dFfn6IQRjwL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VKtsO2cPx0c"
   },
   "source": [
    "# Augment Gemini Output with Vector Embeddings from BigQuery\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ExfeGcm9Iu5"
   },
   "source": [
    "|-|-|-|\n",
    "|-|-|-|\n",
    "|Author(s) | [Logan Ramalingam](https://github.com/logan-google)\n",
    "|Modified for Hands-on(s) | [Wildan Putra](https://www.linkedin.com/in/wildanputra/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja124yztPhGw"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook shows how to use BigQuery to create generate embeddings from text in a BigQuery table, store them within BigQuery, and then use the embeddings to augment the results from LLM in Vector Search.\n",
    "\n",
    "In this notebook, we create text embeddings for publicly available abstracts from [patents data](https://console.cloud.google.com/marketplace/product/google_patents_public_datasets/google-patents-public-data) and use them in our LLM search. Google Patents Public Data, provided by IFI CLAIMS Patent Services, is a worldwide bibliographic and US full-text dataset of patent publications.\n",
    "\n",
    "\n",
    "```patents-public-data.google_patents_research.publications```\n",
    "\n",
    "This notebook references the steps mentioned in [Perform semantic search and retrieval-augmented generation](https://cloud.google.com/bigquery/docs/vector-index-text-search-tutorial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1U3CtPWTGTO"
   },
   "source": [
    "## Required roles and permissions\n",
    "\n",
    "To create a connection, you need membership in the following Identity and Access Management (IAM) role:\n",
    "\n",
    "* ```roles/bigquery.connectionAdmin```\n",
    "\n",
    "To grant permissions to the connection's service account, you need the following permission:\n",
    "\n",
    "* ```resourcemanager.projects.setIamPolicy```\n",
    "\n",
    "The IAM permissions needed in this tutorial for the remaining BigQuery operations are included in the following two roles:\n",
    "\n",
    "\n",
    "*   BigQuery Data Editor (```roles/bigquery.dataEditor```) to create models, tables, and indexes.\n",
    "\n",
    "*   BigQuery User (```roles/bigquery.user```) to run BigQuery jobs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UyVG5euTqOc"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9DON_o2Tvvx"
   },
   "source": [
    "### Install Vertex AI SDK and other required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Oqy-9gVcO8KW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -oogle-api-core (/opt/conda/lib/python3.10/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --user --quiet google-cloud-aiplatform google-cloud-bigquery lxml google-cloud-bigquery-connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDAU3-1SUMwM"
   },
   "source": [
    "## Set Google Cloud project information and initialize BigQuery Connect\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CBTVwIiHO_NB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Google Cloud Project ID\n",
    "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
    "\n",
    "YOUR_NAME = \"your-name\"\n",
    "\n",
    "# BigQuery Dataset for storing embeddings and model\n",
    "DATASET_ID = f\"bq_vector_embeddings_{YOUR_NAME}\"  # @param {type:\"string\"}\n",
    "\n",
    "# BigQuery Region\n",
    "REGION = \"US\"  # @param {type: \"string\"}\n",
    "\n",
    "# BigQuery Connection name\n",
    "CONN_NAME = f\"bqml_llm_conn_{YOUR_NAME}\"\n",
    "\n",
    "# Embeddings Remote Model name in BigQuery\n",
    "EMBEDDINGS_MODEL_ID = \"llm_gecko\"  # @param {type:\"string\"}\n",
    "\n",
    "# Embeddings Table name in BigQuery\n",
    "EMBEDDINGS_TABLE_ID = \"embeddings\"  # @param {type:\"string\"}\n",
    "\n",
    "# LLM Remote Model name in BigQuery\n",
    "LLM_MODEL_ID = \"llm_gemini\"  # @param {type:\"string\"}\n",
    "\n",
    "# Embeddings Model to use\n",
    "EMBEDDINGS_ENDPOINT_TYPE = \"textembedding-gecko@002\"  # @param {type:\"string\"}\n",
    "\n",
    "# LLM Model to use\n",
    "LLM_ENDPOINT_TYPE = \"gemini-pro\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2SUO-szePFC_",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# Set the project id\n",
    "! gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3YexMilEk7A"
   },
   "source": [
    "## Import libraries\n",
    "\n",
    "Let's start by importing the libraries that we will need for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "khvtJTNwPLQB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_connection_v1 as bq_connection\n",
    "from google.cloud.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4JHJsIgWAYY"
   },
   "source": [
    "## Setup BigQuery Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd-CU5BtvzYI"
   },
   "source": [
    "### Initialize Google BigQuery Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aXveDrBtvyr-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFSqGN9JWK25"
   },
   "source": [
    "### Wrapper to use BigQuery client to run query and return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6hYtolHcPOgz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_bq_query(sql: str):\n",
    "    \"\"\"\n",
    "    Input: SQL query, as a string, to execute in BigQuery\n",
    "    Returns the query results or error, if any\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_job = client.query(sql)\n",
    "        result = query_job.result()\n",
    "        print(f\"JOB ID: {query_job.job_id} STATUS: {query_job.state}\")\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jem8DhWWMx0e"
   },
   "source": [
    "### Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ew-5kjpJMw00",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tridorian-wildan-sandbox-dev.bq_vector_embeddings already exists\n"
     ]
    }
   ],
   "source": [
    "# Set dataset_id to the ID of the dataset to create.\n",
    "dataset = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
    "\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset_object = bigquery.Dataset(dataset)\n",
    "\n",
    "# Specify the geographic location where the dataset should reside.\n",
    "dataset_object.location = \"US\"\n",
    "\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "try:\n",
    "    client.get_dataset(dataset_object)  # Make an API request.\n",
    "    print(f\"Dataset {dataset} already exists\")\n",
    "except NotFound:\n",
    "    dataset = client.create_dataset(dataset_object, timeout=30)  # Make an API request.\n",
    "    print(f\"Created dataset {client.project}.{dataset_object.dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0qek5a1W2Pl"
   },
   "source": [
    "### Create BigQuery Cloud resource connection\n",
    "\n",
    "You will need to create a [Cloud resource connection](https://cloud.google.com/bigquery/docs/create-cloud-resource-connection) to enable BigQuery to interact with Vertex AI services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "AYZb179IPQG6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serviceAccount:bqcx-330195729553-y58w@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "conn_client = bq_connection.ConnectionServiceClient()\n",
    "new_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}\"\n",
    "exists_conn_parent = f\"projects/{PROJECT_ID}/locations/{REGION}/connections/{CONN_NAME}\"\n",
    "cloud_resource_properties = bq_connection.CloudResourceProperties({})\n",
    "\n",
    "# Try to use an existing connection if one already exists. If not, create a new one.\n",
    "try:\n",
    "    request = conn_client.get_connection(\n",
    "        request=bq_connection.GetConnectionRequest(name=exists_conn_parent)\n",
    "    )\n",
    "    conn_service_account = f\"serviceAccount:{request.cloud_resource.service_account_id}\"\n",
    "except Exception:\n",
    "    connection = bq_connection.types.Connection(\n",
    "        {\"friendly_name\": CONN_NAME, \"cloud_resource\": cloud_resource_properties}\n",
    "    )\n",
    "    request = bq_connection.CreateConnectionRequest(\n",
    "        {\n",
    "            \"parent\": new_conn_parent,\n",
    "            \"connection_id\": CONN_NAME,\n",
    "            \"connection\": connection,\n",
    "        }\n",
    "    )\n",
    "    response = conn_client.create_connection(request)\n",
    "    conn_service_account = (\n",
    "        f\"serviceAccount:{response.cloud_resource.service_account_id}\"\n",
    "    )\n",
    "print(conn_service_account)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jieSbg0jXAUK"
   },
   "source": [
    "### Set permissions for Service Account\n",
    "The resource connection service account requires certain project-level permissions which are outlined in the <a href=\"https://cloud.google.com/bigquery/docs/bigquery-ml-remote-model-tutorial#set_up_access\" target=\"_blank\">Vertex AI function documentation</a>.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** If you are using Vertex AI Workbench, the service account used by Vertex AI may not have sufficient permissions to add IAM policy bindings.\n",
    "\n",
    "The [IAM Grant Access](https://cloud.google.com/iam/docs/granting-changing-revoking-access#grant-single-role) page gives instructions on how these policy bindings can be added using Cloud Shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5aNt3ZAPSJI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={conn_service_account} --role='roles/serviceusage.serviceUsageConsumer'\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={conn_service_account} --role='roles/bigquery.connectionUser'\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --condition=None --no-user-output-enabled --member={conn_service_account} --role='roles/aiplatform.user'\n",
    "!gcloud services enable bigqueryconnection.googleapis.com\n",
    "# wait 60 seconds, give IAM updates time to propagate, otherwise, following cells will fail\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUe5waT9XS0l"
   },
   "source": [
    "# Configure Vertex AI Embeddings Model in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__1U_CJkYTNS"
   },
   "source": [
    "## Create the remote model for text embeddings generation\n",
    "Create a remote model that represents a hosted Vertex AI text embeddings generation model.\n",
    "\n",
    "The query takes several seconds to complete, after which the model ```EMBEDDINGS_MODEL_ID``` appears in the ```DATASET_ID``` in the Explorer pane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rOuKE6z9GPIJ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: 0cec0c00-3883-42c0-bd20-806abefeb0e0 STATUS: DONE\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"CREATE OR REPLACE MODEL\n",
    "            `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_MODEL_ID}`\n",
    "          REMOTE WITH CONNECTION\n",
    "            `{PROJECT_ID}.{REGION}.{CONN_NAME}`\n",
    "          OPTIONS (ENDPOINT = '{EMBEDDINGS_ENDPOINT_TYPE}');\"\"\"\n",
    "result = run_bq_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Baocs6-vYzBf"
   },
   "source": [
    "## Generate text embeddings\n",
    "Generate text embeddings from patent abstracts using the ```ML.GENERATE_TEXT_EMBEDDING``` function, and then write them to a BigQuery table so that they can be searched.\n",
    "\n",
    "**Note: Query might take up to 10 minutes to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "i6_BDJn9GRAi",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: f7624749-246d-4d7b-b733-e69ef8a528f1 STATUS: DONE\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "      CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}` AS\n",
    "      SELECT * FROM ML.GENERATE_TEXT_EMBEDDING(\n",
    "        MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_MODEL_ID}`,\n",
    "        (\n",
    "          SELECT *, abstract AS content\n",
    "          FROM `patents-public-data.google_patents_research.publications`\n",
    "          WHERE LENGTH(abstract) > 0 AND LENGTH(title) > 0 AND country = 'Singapore'\n",
    "        )\n",
    "      )\n",
    "      WHERE ARRAY_LENGTH(text_embedding) > 0;\n",
    "      \"\"\"\n",
    "result = run_bq_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "725vcaYAY_KA"
   },
   "source": [
    "## Create Vector index\n",
    "\n",
    "A vector index is a data structure designed to let the ```VECTOR_SEARCH``` function perform a more efficient vector search of embeddings. When ```VECTOR_SEARCH``` is able to use a vector index, the function uses the Approximate Nearest Neighbor search technique to help improve search performance, with the trade-off of reducing recall and thus returning more approximate results.\n",
    "\n",
    "**NOTE: Query might take up to 5 minutes to run.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "u_9ndU0BPbPv",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: 69c20743-cbaf-42da-b224-0fba95c9f973 STATUS: DONE\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"CREATE OR REPLACE VECTOR INDEX my_index ON `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}`(text_embedding) OPTIONS(index_type = 'IVF',\n",
    "distance_type = 'COSINE',   ivf_options = '{{\"num_lists\":500}}')\"\"\"\n",
    "result = run_bq_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_JRpw5uZb79"
   },
   "source": [
    "### Verify vector index creation\n",
    "\n",
    "The vector index is populated asynchronously. You can check whether the index is ready to be used by querying the ```INFORMATION_SCHEMA.VECTOR_INDEXES``` view and verifying that the coverage_percentage column value is greater than 0 and the ```last_refresh_time``` column value isn't ```NULL```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PWe97Sk5PdSe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: 7961cc4c-e490-4ac9-8076-6d76195abefd STATUS: DONE\n",
      "   table_name index_name index_status  coverage_percentage last_refresh_time  \\\n",
      "0  embeddings   my_index       ACTIVE                    0               NaT   \n",
      "\n",
      "  disable_reason  \n",
      "0           None  \n"
     ]
    }
   ],
   "source": [
    "# Check vector index creation status, 'coverage_percentage' should be 100\n",
    "sql = f\"\"\"\n",
    "\n",
    "    SELECT table_name, index_name, index_status, coverage_percentage, last_refresh_time, disable_reason\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.INFORMATION_SCHEMA.VECTOR_INDEXES`\n",
    "    WHERE table_name = '{EMBEDDINGS_TABLE_ID}'\n",
    "    \"\"\"\n",
    "\n",
    "result = run_bq_query(sql).to_dataframe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAcxPdClaRMQ"
   },
   "source": [
    "## Perform a text similarity search using the vector index\n",
    "\n",
    "Use the ```VECTOR_SEARCH``` function to search for the top 5 relevant patents that match embeddings generated from a text query. The model you use to generate the embeddings in this query must be the same as the one you use to generate the embeddings in the table you are comparing against, otherwise the search results won't be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6-5r-0q7Pern",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: ab49ffce-f41a-4c5b-90a8-9f4a57354a1a STATUS: DONE\n",
      "                         query  \\\n",
      "0  improving password security   \n",
      "1  improving password security   \n",
      "2  improving password security   \n",
      "3  improving password security   \n",
      "4  improving password security   \n",
      "\n",
      "                                             content  distance  \n",
      "0  Methods for improving security in data storage...  0.104066  \n",
      "1  PASSSWORD MANAGEMENT SYSTEM AND PROCESS There ...  0.112056  \n",
      "2  METHOD AND APPARATUS FOR UNLOCKING USER INTERF...  0.119292  \n",
      "3  An active new password entry dialog provides a...  0.119728  \n",
      "4  An electronic device includes password protect...  0.119735  \n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "  SELECT\n",
    "    query.query,\n",
    "    base.content,\n",
    "    distance\n",
    "  FROM\n",
    "    VECTOR_SEARCH( TABLE `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}`,\n",
    "      'text_embedding',\n",
    "      (\n",
    "      SELECT\n",
    "        text_embedding,\n",
    "        content AS query\n",
    "      FROM\n",
    "        ML.GENERATE_TEXT_EMBEDDING( MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_MODEL_ID}`,\n",
    "          (\n",
    "          SELECT 'improving password security' AS content))\n",
    "      ),\n",
    "      top_k => 5,\n",
    "      OPTIONS => '{{\"fraction_lists_to_search\":0.01}}');\"\"\"\n",
    "\n",
    "result = run_bq_query(sql).to_dataframe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQCg_qDzbGV3"
   },
   "source": [
    "# Generate text using embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A4OZzdRbaDK"
   },
   "source": [
    "## Create the remote model for text generation\n",
    "\n",
    "Create a remote model that represents a hosted Gemini Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fWrK3FH9H99l",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: a71d2cc0-5451-46ed-80d3-2a3c3f14a15b STATUS: DONE\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"\n",
    "      CREATE OR REPLACE MODEL\n",
    "        `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_ID}`\n",
    "        REMOTE WITH CONNECTION\n",
    "          `{PROJECT_ID}.{REGION}.{CONN_NAME}`\n",
    "        OPTIONS (ENDPOINT = '{LLM_ENDPOINT_TYPE}');\n",
    "      \"\"\"\n",
    "result = run_bq_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dziHo0LQbrHv"
   },
   "source": [
    "## Generate text augmented by vector search results\n",
    "\n",
    "Feed the search results as prompts to generate text with the ```ML.GENERATE_TEXT``` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "uqH_qvy_cKot",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Project Ideas to Improve User Password Security:\n",
      "\n",
      "**1. Dynamic Password Generation and Synchronization:**\n",
      "\n",
      "* **Patent Title:** Data storage device security method and apparatus\n",
      "* **Patent URL:** [Link to Patent]\n",
      "* **Project Idea:** Develop a system that dynamically generates and synchronizes encrypted passwords between user devices and data storage systems. This system would eliminate the need for users to remember static passwords, reducing the risk of password theft and brute-force attacks.\n",
      "\n",
      "**2. Context-Aware Password Management:**\n",
      "\n",
      "* **Patent Title:** Passsword management system and process\n",
      "* **Patent URL:** [Link to Patent]\n",
      "* **Project Idea:** Create a password management system that adapts to user context, such as location, time of day, and device type. This system could automatically generate strong passwords based on context, reducing the burden on users to remember multiple complex passwords.\n",
      "\n",
      "**3. Multi-Factor Authentication with Biometric Verification:**\n",
      "\n",
      "* **Patent Title:** Method and apparatus for unlocking user interface\n",
      "* **Patent URL:** [Link to Patent]\n",
      "* **Project Idea:** Implement multi-factor authentication with biometric verification for user logins. This system would require users to provide multiple forms of authentication, such as a password, fingerprint, or facial recognition, making it significantly harder for attackers to gain unauthorized access.\n",
      "\n",
      "**4. Active Password Policy Enforcement with Visual Feedback:**\n",
      "\n",
      "* **Patent Title:** Active new password entry dialog with compact visual indication of adherence to password policy\n",
      "* **Patent URL:** [Link to Patent]\n",
      "* **Project Idea:** Develop an active password entry dialog that provides real-time feedback on password strength and adherence to password policies. This system would help users create strong passwords that meet security requirements, reducing the risk of weak passwords.\n",
      "\n",
      "**5. User-Defined Passwords with Versioning for Recall Assistance:**\n",
      "\n",
      "* **Patent Title:** User-defined passwords having associated unique version data to assist user recall of the password\n",
      "* **Patent URL:** [Link to Patent]\n",
      "* **Project Idea:** Allow users to define their own passwords and associate them with unique version data. This data could be used to help users recall their passwords if they forget them, reducing the need for password resets and improving user experience.\n",
      "\n",
      "These are just a few ideas for projects that could improve user password security. By leveraging existing patents and technologies, we can develop innovative solutions that make it easier for users to protect their accounts and data.\n"
     ]
    }
   ],
   "source": [
    "sql = f\"\"\"SELECT ml_generate_text_llm_result AS generated, prompt\n",
    "FROM ML.GENERATE_TEXT(\n",
    "  MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_ID}`,\n",
    "  (\n",
    "    SELECT CONCAT(\n",
    "      'Propose some project ideas to improve user password security using the context below. Add the patent title and url to each idea: ',\n",
    "      STRING_AGG(\n",
    "        FORMAT(\"patent title: %s, patent abstract: %s\", base.title, base.abstract))\n",
    "      ) AS prompt,\n",
    "    FROM VECTOR_SEARCH(\n",
    "      TABLE `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}`, 'text_embedding',\n",
    "      (\n",
    "        SELECT text_embedding, content AS query\n",
    "        FROM ML.GENERATE_TEXT_EMBEDDING(\n",
    "          MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_MODEL_ID}`,\n",
    "         (SELECT 'improving password security' AS content)\n",
    "        )\n",
    "      ),\n",
    "    top_k => 5, options => '{{\"fraction_lists_to_search\": 0.01}}')\n",
    "  ),\n",
    "  STRUCT(600 AS max_output_tokens, TRUE AS flatten_json_output));\"\"\"\n",
    "\n",
    "query_job = client.query(sql)\n",
    "rows = query_job.result()\n",
    "\n",
    "for row in rows:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyVndOMsw7CU"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "Clean up resources created in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UZOryN4Nw6vW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB ID: b9fd6725-d373-4cf6-b8e7-d1b04600712c STATUS: DONE\n",
      "JOB ID: 8781b61a-9a5f-4f97-b272-5413a6af6a16 STATUS: DONE\n",
      "JOB ID: 6bbb1b4d-014d-4943-9b07-4dc265ef8ded STATUS: DONE\n",
      "JOB ID: 0a0f35a1-e6c5-486c-9a69-aee62b6cfcdb STATUS: DONE\n"
     ]
    }
   ],
   "source": [
    "# Delete Vector Index\n",
    "sql = f\"\"\"DROP VECTOR INDEX my_index ON `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}`\"\"\"\n",
    "result = run_bq_query(sql)\n",
    "\n",
    "# Delete Gemini Model\n",
    "sql = f\"\"\"DROP MODEL `{PROJECT_ID}.{DATASET_ID}.{LLM_MODEL_ID}`\"\"\"\n",
    "result = run_bq_query(sql)\n",
    "\n",
    "# Delete Embeddings Model\n",
    "sql = f\"\"\"DROP MODEL `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_MODEL_ID}`\"\"\"\n",
    "result = run_bq_query(sql)\n",
    "\n",
    "# Delete Embeddings Table\n",
    "sql = f\"\"\"DROP TABLE `{PROJECT_ID}.{DATASET_ID}.{EMBEDDINGS_TABLE_ID}`\"\"\"\n",
    "result = run_bq_query(sql)\n",
    "\n",
    "# Delete BigQuery Connection\n",
    "request = bq_connection.DeleteConnectionRequest({\"name\": exists_conn_parent})\n",
    "response = conn_client.delete_connection(request)\n",
    "\n",
    "# Delete Dataset\n",
    "client.delete_dataset(dataset_object, delete_contents=True, not_found_ok=True)\n",
    "\n",
    "# Close BigQuery Connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "rag_vector_embedding_in_bigquery.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
